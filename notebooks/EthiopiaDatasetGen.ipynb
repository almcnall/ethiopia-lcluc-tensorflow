{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ethiopia Dataset Gen\n",
    "\n",
    "Generate and prepare Ethiopia Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_filename = 'train_data_ethiopia_v2.csv'\n",
    "nodata_val = -10001\n",
    "max_classes = 6\n",
    "bands = ['CB', 'B', 'G', 'Y', 'R', 'RE', 'NIR1', 'NIR2']\n",
    "dataset_metadata = {\n",
    "    'WV03_20141024_data.tif': {\n",
    "        '0': 50000,\n",
    "        '1': 50000,\n",
    "        '2': 0,\n",
    "        '3': 825,\n",
    "        '4': 65000,\n",
    "        '5': 0,\n",
    "    },\n",
    "    'WV03_20141118_data.tif': {\n",
    "        '0': 50000,\n",
    "        '1': 50000,\n",
    "        '2': 65000,\n",
    "        '3': 96703,\n",
    "        '4': 65000,\n",
    "        '5': 0,\n",
    "    },\n",
    "    'WV03_20141207_data.tif': {\n",
    "        '0': 50000,\n",
    "        '1': 50000,\n",
    "        '2': 65000,\n",
    "        '3': 95703,\n",
    "        '4': 65000,\n",
    "        '5': 0,\n",
    "    },\n",
    "    'WV03_20180114_data.tif': {\n",
    "        '0': 50000,\n",
    "        '1': 50000,\n",
    "        '2': 65000,\n",
    "        '3': 7769,\n",
    "        '4': 0,\n",
    "        '5': 186796,\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Data Location Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#images_path: str = '/att/pubrepo/ILAB/projects/Ethiopia/ethiopia-lcluc/data/images'\n",
    "#labels_path: str = '/att/pubrepo/ILAB/projects/Ethiopia/ethiopia-lcluc/data/labels'\n",
    "images_path: str = '/adapt/nobackup/projects/ilab/projects/Ethiopia/LCLUC_Ethiopia/data/images'\n",
    "labels_path: str = '/adapt/nobackup/projects/ilab/projects/Ethiopia/LCLUC_Ethiopia/data/labels'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_list: list = sorted(glob.glob(os.path.join(images_path, '*.tif')))\n",
    "labels_list: list = sorted(glob.glob(os.path.join(labels_path, '*.tif')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 8069, 2240) (8069, 2240) [ 0  1  3  4 14] WV03_20141024_data.tif\n",
      "Class 0 points to extract 50000\n",
      "Class 0: (13875423,) (13875423,)\n",
      "50000\n",
      "Class 1 points to extract 50000\n",
      "Class 1: (3734985,) (3734985,)\n",
      "50000\n",
      "Class 2 points to extract 0\n",
      "Class 2: (0,) (0,)\n",
      "0\n",
      "Class 3 points to extract 825\n",
      "Class 3: (830,) (830,)\n",
      "825\n",
      "Class 4 points to extract 65000\n",
      "Class 4: (444610,) (444610,)\n",
      "65000\n",
      "Class 5 points to extract 0\n",
      "Class 5: (0,) (0,)\n",
      "0\n",
      "(8, 8069, 6210) (8069, 6210) [ 0  1  2  3  4 14] WV03_20141118_data.tif\n",
      "Class 0 points to extract 50000\n",
      "Class 0: (36815318,) (36815318,)\n",
      "50000\n",
      "Class 1 points to extract 50000\n",
      "Class 1: (11587674,) (11587674,)\n",
      "50000\n",
      "Class 2 points to extract 65000\n",
      "Class 2: (147723,) (147723,)\n",
      "65000\n",
      "Class 3 points to extract 96703\n",
      "Class 3: (206031,) (206031,)\n",
      "96703\n",
      "Class 4 points to extract 65000\n",
      "Class 4: (1300005,) (1300005,)\n",
      "65000\n",
      "Class 5 points to extract 0\n",
      "Class 5: (0,) (0,)\n",
      "0\n",
      "(8, 8069, 7108) (8069, 7108) [ 0  1  2  3  4 14] WV03_20141207_data.tif\n",
      "Class 0 points to extract 50000\n",
      "Class 0: (42280608,) (42280608,)\n",
      "YES\n",
      "YES\n",
      "YES\n",
      "YES\n",
      "YES\n",
      "YES\n",
      "YES\n",
      "YES\n",
      "YES\n",
      "YES\n",
      "YES\n",
      "YES\n",
      "50000\n",
      "Class 1 points to extract 50000\n",
      "Class 1: (13080847,) (13080847,)\n",
      "YES\n",
      "YES\n",
      "YES\n",
      "50000\n",
      "Class 2 points to extract 65000\n",
      "Class 2: (147058,) (147058,)\n",
      "65000\n",
      "Class 3 points to extract 95703\n",
      "Class 3: (206861,) (206861,)\n",
      "95703\n",
      "Class 4 points to extract 65000\n",
      "Class 4: (1579793,) (1579793,)\n",
      "YES\n",
      "YES\n",
      "YES\n",
      "YES\n",
      "YES\n",
      "YES\n",
      "YES\n",
      "YES\n",
      "YES\n",
      "YES\n",
      "YES\n",
      "YES\n",
      "YES\n",
      "65000\n",
      "Class 5 points to extract 0\n",
      "Class 5: (0,) (0,)\n",
      "0\n",
      "(8, 437, 4302) (437, 4302) [ 0  1  2  3  5 14] WV03_20180114_data.tif\n",
      "Class 0 points to extract 50000\n",
      "Class 0: (1501394,) (1501394,)\n",
      "50000\n",
      "Class 1 points to extract 50000\n",
      "Class 1: (75788,) (75788,)\n",
      "50000\n",
      "Class 2 points to extract 65000\n",
      "Class 2: (108082,) (108082,)\n",
      "65000\n",
      "Class 3 points to extract 7769\n",
      "Class 3: (7769,) (7769,)\n",
      "7769\n",
      "Class 4 points to extract 0\n",
      "Class 4: (0,) (0,)\n",
      "0\n",
      "Class 5 points to extract 186796\n",
      "Class 5: (186796,) (186796,)\n",
      "186796\n"
     ]
    }
   ],
   "source": [
    "# create dataframe and list to store points\n",
    "list_points = []\n",
    "df_points = pd.DataFrame(columns=bands + ['CLASS'])\n",
    "    \n",
    "for image,label in zip(images_list, labels_list):\n",
    "    \n",
    "    # open imagery\n",
    "    filename = image.split('/')[-1]\n",
    "    image = xr.open_rasterio(image).values\n",
    "    label = xr.open_rasterio(label).values\n",
    "    \n",
    "    # Some preprocessing\n",
    "    label = np.squeeze(label) if len(label.shape) != 2 else label\n",
    "    label = label - 1 if np.min(label) == 1 else label\n",
    "    print(image.shape, label.shape, np.unique(label), filename)\n",
    "\n",
    "    for c in range(max_classes):\n",
    "\n",
    "        indices = 0\n",
    "        selected_points = 0\n",
    "        num_points = dataset_metadata[filename][str(c)]\n",
    "        print(f'Class {str(c)} points to extract {str(num_points)}')\n",
    "\n",
    "        x_indices, y_indices = np.where(label == c)  # we extract all class c points from the imagery\n",
    "        x_indices, y_indices = shuffle(x_indices, y_indices)  # we make sure values are fully shuffled\n",
    "        print(f\"Class {c}:\", x_indices.shape, y_indices.shape)\n",
    "\n",
    "        if x_indices.shape[0] != 0:\n",
    "            try:\n",
    "                while selected_points < num_points:\n",
    "\n",
    "                    sv, lv = image[:, x_indices[indices], y_indices[indices]], \\\n",
    "                        int(label[x_indices[indices], y_indices[indices]])\n",
    "\n",
    "                    if sv[0] != nodata_val:\n",
    "\n",
    "                        list_points.append(\n",
    "                            pd.DataFrame(\n",
    "                                [np.append(sv, [lv])],\n",
    "                                columns=list(df_points.columns))\n",
    "                        )                    \n",
    "                        selected_points += 1\n",
    "                    else:\n",
    "                        print(\"YES\")\n",
    "                    indices += 1\n",
    "            except IndexError:\n",
    "                pass\n",
    "\n",
    "        print(selected_points)\n",
    "\n",
    "df_points = pd.concat(list_points)\n",
    "df_points.to_csv(output_filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ilab-kernel]",
   "language": "python",
   "name": "conda-env-ilab-kernel-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
